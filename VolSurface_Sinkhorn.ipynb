{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0be2b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.optimize import minimize\n",
    "import scipy.integrate as integrate\n",
    "from scipy import special\n",
    "from scipy.special import erf\n",
    "from scipy import optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8274a2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calls</th>\n",
       "      <th>Last Sale</th>\n",
       "      <th>Net</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Volume</th>\n",
       "      <th>IV</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Open Interest</th>\n",
       "      <th>Strike</th>\n",
       "      <th>Strike/Spot</th>\n",
       "      <th>Mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD230414C00083000</td>\n",
       "      <td>9.72</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>9.55</td>\n",
       "      <td>9.80</td>\n",
       "      <td>166</td>\n",
       "      <td>0.4442</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>293</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.899242</td>\n",
       "      <td>9.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMD230414C00084000</td>\n",
       "      <td>9.05</td>\n",
       "      <td>0.150</td>\n",
       "      <td>8.65</td>\n",
       "      <td>8.85</td>\n",
       "      <td>22</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>225</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.910076</td>\n",
       "      <td>8.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMD230414C00085000</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.075</td>\n",
       "      <td>7.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>134</td>\n",
       "      <td>0.4427</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>867</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.920910</td>\n",
       "      <td>7.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD230414C00086000</td>\n",
       "      <td>7.00</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>6.80</td>\n",
       "      <td>7.00</td>\n",
       "      <td>77</td>\n",
       "      <td>0.4352</td>\n",
       "      <td>0.8782</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>569</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.931744</td>\n",
       "      <td>6.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD230414C00087000</td>\n",
       "      <td>6.20</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>5.95</td>\n",
       "      <td>6.15</td>\n",
       "      <td>101</td>\n",
       "      <td>0.4259</td>\n",
       "      <td>0.8417</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>544</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.942579</td>\n",
       "      <td>6.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AMD230414C00088000</td>\n",
       "      <td>5.50</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>5.15</td>\n",
       "      <td>5.30</td>\n",
       "      <td>192</td>\n",
       "      <td>0.4269</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>457</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.953413</td>\n",
       "      <td>5.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMD230414C00089000</td>\n",
       "      <td>4.50</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.50</td>\n",
       "      <td>165</td>\n",
       "      <td>0.4155</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>934</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.964247</td>\n",
       "      <td>4.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMD230414C00090000</td>\n",
       "      <td>3.76</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.80</td>\n",
       "      <td>817</td>\n",
       "      <td>0.4147</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>1864</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.975081</td>\n",
       "      <td>3.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AMD230414C00091000</td>\n",
       "      <td>3.07</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.15</td>\n",
       "      <td>1194</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>0.6223</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>1272</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>3.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AMD230414C00092000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.50</td>\n",
       "      <td>8647</td>\n",
       "      <td>0.4024</td>\n",
       "      <td>0.5529</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>1637</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>2.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AMD230414C00093000</td>\n",
       "      <td>1.98</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.99</td>\n",
       "      <td>8374</td>\n",
       "      <td>0.3973</td>\n",
       "      <td>0.4806</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>2744</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.007584</td>\n",
       "      <td>1.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AMD230414C00094000</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2590</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.4081</td>\n",
       "      <td>0.0719</td>\n",
       "      <td>1484</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.018418</td>\n",
       "      <td>1.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AMD230414C00095000</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.17</td>\n",
       "      <td>7877</td>\n",
       "      <td>0.3879</td>\n",
       "      <td>0.3382</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>5239</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.029252</td>\n",
       "      <td>1.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AMD230414C00096000</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1653</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.2738</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>2729</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.040087</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AMD230414C00097000</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1712</td>\n",
       "      <td>0.3856</td>\n",
       "      <td>0.2169</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>2929</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.050921</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AMD230414C00098000</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2173</td>\n",
       "      <td>0.3871</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>3237</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.061755</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AMD230414C00099000</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1048</td>\n",
       "      <td>0.3888</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>1770</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.072589</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AMD230414C00100000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2154</td>\n",
       "      <td>0.3910</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>5141</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.083424</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AMD230414C00101000</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>560</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>1258</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.094258</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AMD230414C00102000</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>708</td>\n",
       "      <td>0.4024</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>1659</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.105092</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Calls  Last Sale    Net   Bid   Ask  Volume      IV   Delta   \n",
       "0   AMD230414C00083000       9.72 -0.105  9.55  9.80     166  0.4442  0.9452  \\\n",
       "1   AMD230414C00084000       9.05  0.150  8.65  8.85      22  0.4504  0.9287   \n",
       "2   AMD230414C00085000       8.10  0.075  7.70  7.90     134  0.4427  0.9068   \n",
       "3   AMD230414C00086000       7.00 -0.125  6.80  7.00      77  0.4352  0.8782   \n",
       "4   AMD230414C00087000       6.20 -0.125  5.95  6.15     101  0.4259  0.8417   \n",
       "5   AMD230414C00088000       5.50 -0.050  5.15  5.30     192  0.4269  0.7974   \n",
       "6   AMD230414C00089000       4.50 -0.300  4.40  4.50     165  0.4155  0.7456   \n",
       "7   AMD230414C00090000       3.76 -0.340  3.70  3.80     817  0.4147  0.6869   \n",
       "8   AMD230414C00091000       3.07 -0.380  3.05  3.15    1194  0.4062  0.6223   \n",
       "9   AMD230414C00092000       2.50 -0.365  2.48  2.50    8647  0.4024  0.5529   \n",
       "10  AMD230414C00093000       1.98 -0.375  1.95  1.99    8374  0.3973  0.4806   \n",
       "11  AMD230414C00094000       1.52 -0.380  1.52  1.54    2590  0.3928  0.4081   \n",
       "12  AMD230414C00095000       1.16 -0.350  1.15  1.17    7877  0.3879  0.3382   \n",
       "13  AMD230414C00096000       0.85 -0.330  0.84  0.89    1653  0.3867  0.2738   \n",
       "14  AMD230414C00097000       0.63 -0.285  0.62  0.64    1712  0.3856  0.2169   \n",
       "15  AMD230414C00098000       0.46 -0.235  0.45  0.47    2173  0.3871  0.1685   \n",
       "16  AMD230414C00099000       0.32 -0.215  0.32  0.34    1048  0.3888  0.1286   \n",
       "17  AMD230414C00100000       0.24 -0.165  0.23  0.24    2154  0.3910  0.0974   \n",
       "18  AMD230414C00101000       0.18 -0.135  0.16  0.18     560  0.3958  0.0735   \n",
       "19  AMD230414C00102000       0.13 -0.105  0.12  0.14     708  0.4024  0.0555   \n",
       "\n",
       "     Gamma  Open Interest  Strike  Strike/Spot    Mid  \n",
       "0   0.0172            293    83.0     0.899242  9.675  \n",
       "1   0.0217            225    84.0     0.910076  8.750  \n",
       "2   0.0272            867    85.0     0.920910  7.800  \n",
       "3   0.0337            569    86.0     0.931744  6.900  \n",
       "4   0.0409            544    87.0     0.942579  6.050  \n",
       "5   0.0483            457    88.0     0.953413  5.225  \n",
       "6   0.0556            934    89.0     0.964247  4.450  \n",
       "7   0.0622           1864    90.0     0.975081  3.750  \n",
       "8   0.0677           1272    91.0     0.985915  3.100  \n",
       "9   0.0714           1637    92.0     0.996750  2.490  \n",
       "10  0.0730           2744    93.0     1.007584  1.970  \n",
       "11  0.0719           1484    94.0     1.018418  1.530  \n",
       "12  0.0683           5239    95.0     1.029252  1.160  \n",
       "13  0.0625           2729    96.0     1.040087  0.865  \n",
       "14  0.0552           2929    97.0     1.050921  0.630  \n",
       "15  0.0473           3237    98.0     1.061755  0.460  \n",
       "16  0.0392           1770    99.0     1.072589  0.330  \n",
       "17  0.0319           5141   100.0     1.083424  0.235  \n",
       "18  0.0255           1258   101.0     1.094258  0.170  \n",
       "19  0.0202           1659   102.0     1.105092  0.130  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "amd_quotes = pd.read_csv('amd_quotedata.csv', parse_dates=['Expiration Date'], index_col=['Expiration Date'])\n",
    "amd_calls = amd_quotes.iloc[:,0:11]\n",
    "\n",
    "S0 = 92.3\n",
    "amd_calls['Strike/Spot'] = amd_calls['Strike']/S0_amd\n",
    "amd_calls['Mid'] = (amd_calls['Bid']+amd_calls['Ask'])/2\n",
    "C1 = amd_calls.loc['2023-04-14']\n",
    "C1 = C1.reset_index(drop=True)\n",
    "C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4b788f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iv(p,K,T,r,S0):\n",
    "    \"\"\"\n",
    "    Calculate implied volatility using Black-Scholes formula\n",
    "    \n",
    "    Parameters:\n",
    "    p (float): Market price(s) of the option\n",
    "    K (float): Strike price(s) of the option\n",
    "    T (float): Time to expiry of the option, in years\n",
    "    r (float): Risk-free interest rate, as a decimal\n",
    "    S0 (float): Current price of the underlying asset\n",
    "    \"\"\"\n",
    "    \n",
    "    d1 = lambda sigma: (np.log(S0/K) + (r + 0.5*(sigma**2))*T) / (sigma*np.sqrt(T))\n",
    "    d2 = lambda sigma: d1(sigma) - sigma*np.sqrt(T)\n",
    "    option_price = lambda sigma: S0*norm.cdf(d1(sigma)) - K*np.exp(-r*T)*norm.cdf(d2(sigma))\n",
    "    option_price_diff = lambda sigma: option_price(sigma) - p\n",
    "    \n",
    "    return fsolve(option_price_diff, 0.2*np.ones(len(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e0052038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which risk-free interest rate is used?\n",
    "#iv_diff = lambda r: np.linalg.norm(iv(np.array(amd_calls_t1['Mid']),np.array(amd_calls_t1['Strike']),6/252,r,S0) - np.array(amd_calls_t1['IV']))\n",
    "#r_ = minimize(iv_diff, 0.01)\n",
    "#print(r_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b6884a7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = 0.01 # TODO: figure out r\n",
    "ask = np.array(C1['Ask'])\n",
    "bid = np.array(C1['Bid'])\n",
    "mid = np.array(C1['Mid'])\n",
    "K = np.array(C1['Strike'])\n",
    "numK = len(K)\n",
    "t1 = 6/252\n",
    "# Plot data\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(C1['Strike/Spot']), np.array(iv(bid,K,t1,r,S0)), 'b.', label='Bid')\n",
    "ax.plot(np.array(C1['Strike/Spot']), np.array(iv(ask,K,t1,r,S0)), 'g.', label='Ask')\n",
    "ax.plot(np.array(C1['Strike/Spot']), np.array(iv(mid,K,t1,r,S0)), 'r--', label='Mid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "79e15679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.26725329153062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/6f30xmfd3r3br8s467bvpdg40000gn/T/ipykernel_13145/2763409847.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  help_v = (K-S0)/(np.sqrt(2)*sqrtt*sigma)\n"
     ]
    }
   ],
   "source": [
    "def sigma_objective(sigma, S0):\n",
    "    sqrtt = math.sqrt(t1)\n",
    "    help_v = (K-S0)/(np.sqrt(2)*sqrtt*sigma)\n",
    "    B_vec = 0.5*(S0-K)*erf(help_v) + sigma*sqrtt/np.sqrt(2*math.pi)*np.exp(-help_v**2)\n",
    "    return np.sum((B_vec-mid)**2)\n",
    "\n",
    "\n",
    "def calculate_sigma0(S_0):\n",
    "    res = optimize.minimize_scalar(sigma_objective,args = (S_0,))\n",
    "    return res.x\n",
    "\n",
    "sigma0 = calculate_sigma_0(S0)\n",
    "print(sigma_0)\n",
    "\n",
    "\n",
    "#def m_0(s,S0,sigma0,t1): # Joint distribution of S1 and S2\n",
    "    #return (S0 >= 0) *  (1/(np.sqrt(2*math.pi)*(sigma0*S0))) * np.exp(-1/2*((s-S0)/(sigma0*S0))**2)  *  (1/(np.sqrt(2*math.pi)*sigma0*S0*np.sqrt(t1)) * np.exp(-1/2*((s-S0)/(sigma0*S0*np.sqrt(t1)))**2) )\n",
    "\n",
    "def m0(s,S_0,sigma_0,t_1):\n",
    "    #renormalise m_0 on R^+\n",
    "    return norm.pdf(s,S_0,sigma_0*np.sqrt(t_1))/norm.cdf(S_0/(sigma_0*np.sqrt(t_1))) if s>=0 else 0\n",
    "\n",
    "\n",
    "def f1(V,omega):\n",
    "    delta_C_bid = bid - mid\n",
    "    delta_C_ask = ask - mid\n",
    "    l = np.zeros(numK)\n",
    "    \n",
    "    for i in range(numK):\n",
    "        if (V[i]*omega[i] <= delta_C_ask[i]) and (V[i]*omega[i] >= delta_C_bid[i]):\n",
    "            l[i] = V[i]*V[i]*omega[i]/2\n",
    "        elif V[i]*omega[i] > delta_C_ask[i]:\n",
    "            l[i] = delta_C_ask[i]*V[i] - delta_C_ask[i]**2/(2*omega[i])\n",
    "        elif V[i]*omega[i] < delta_C_bid[i]: \n",
    "            l[i] = delta_C_bid[i]*V[i] - delta_C_bid[i]**2/(2*omega[i])\n",
    "            \n",
    "    return l\n",
    "\n",
    "\n",
    "def grad_f1(V,omega):\n",
    "    \"\"\"\n",
    "    Gradient of g1 with respect to V_K\n",
    "    \"\"\"\n",
    "    delta_C_bid = bid - mid\n",
    "    delta_C_ask = ask - mid\n",
    "    g = np.zeros(numK)\n",
    "    \n",
    "    for j in range(numK):\n",
    "        if (V[j]*omega[j] <= delta_C_ask[j]) and (V[j]*omega[j] >= delta_C_bid[j]):\n",
    "            g[j] = V[j]*omega[j]\n",
    "        elif V[j]*omega[j] > delta_C_ask[j]:\n",
    "            g[j] = delta_C_ask[j]\n",
    "        elif V[j]*omega[j] < delta_C_bid[j]: \n",
    "            g[j] = delta_C_bid[j]\n",
    "    \n",
    "    return g\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14bfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8ca6b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def I1(alpha,sigma,s1,K1,K2): \n",
    "    A, B = (K1-s1)/sigma, (K2-s1)/sigma\n",
    "    return 1/2*math.exp((alpha*sigma)**2/2 + alpha*s1) * (special.erf((B-alpha*sigma)/math.sqrt(2)) - special.erf((A-alpha*sigma)/math.sqrt(2)) )\n",
    "\n",
    "#def I2(alpha,sigma,s1,K1,K2):\n",
    "    #A, B = (K1-s1)/sigma, (K2-s1)/sigma\n",
    "    #return sigma*math.exp(alpha*s1) *  (  2*math.exp(A*alpha*sigma-A*A/2) - math.sqrt(2*math.pi)*alpha*sigma*math.exp((alpha*sigma)**2/2)*special.erf((A-alpha*sigma)/math.sqrt(2)) + math.sqrt(2*math.pi)*alpha*sigma*np.exp((alpha*sigma)**2/2)*special.erf((B-alpha*sigma)/np.sqrt(2)) - 2*math.exp(alpha*B*sigma)-B**2/2  )\n",
    "    \n",
    "def I2(alpha,sigma,s1,K1,K2):\n",
    "    A, B = (K1-s1)/sigma, (K2-s1)/sigma\n",
    "    return sigma*math.exp(alpha*s1) * ( 2*(math.exp(A*alpha*sigma-A*A/2) - math.exp(B*alpha*sigma-B*B/2)) + math.sqrt(2*math.pi)*alpha*sigma*math.exp(alpha*sigma*alpha*sigma/2)*(special.erf((B-alpha*sigma)/np.sqrt(2)) - special.erf((A-alpha*sigma)/np.sqrt(2))) )\n",
    "\n",
    "def I2_quad(alpha,sigma,s1,K1,K2):\n",
    "    #return 2*math.sqrt(2*math.pi) * integrate.quad(lambda s2: math.exp(alpha*s2)*(s2-s1) * (1/(math.sqrt(2*math.pi)*sigma))*math.exp(-1/2*((s2-s1)/sigma)**2), K1, K2)\n",
    "    return integrate.quad(lambda s2: math.exp(alpha*s2)*(s2-s1) * (1/(math.sqrt(2*math.pi)*sigma))*math.exp(-1/2*((s2-s1)/sigma)**2), K1, K2)[0]\n",
    "    \n",
    "def I3(alpha,sigma,s1,K1,K2,Q):\n",
    "    A, B = (K1-s1)/sigma, (K2-s1)/sigma\n",
    "    return math.exp(alpha*s1) *  (  2*sigma*math.exp(A*alpha*sigma-A*A/2) - math.sqrt(2*math.pi)*math.exp((alpha*sigma)**2/2)*special.erf((A-alpha*sigma)/math.sqrt(2))*(alpha*sigma**2-Q+s1) + math.sqrt(2*math.pi)*math.exp((alpha*sigma)**2/2)*special.erf((B-alpha*sigma)/math.sqrt(2))*(alpha*sigma**2-Q+s1) - 2*sigma*math.exp(alpha*B*sigma)-B**2/2  ) \n",
    "\n",
    "def I4(alpha,sigma,s1,K1,K2,K,Q):\n",
    "    A, B = (K1-s1)/sigma, (K2-s1)/sigma  \n",
    "    return 2*sigma* (math.exp(alpha*A*sigma-A*A/2)*(sigma*(alpha*sigma+A) - K - Q + 2*s1) + math.exp(-1/2*B*(B-2*alpha*sigma))*(-sigma*(alpha*sigma+B) + K + Q -2*s1))  +  math.sqrt(2*math.pi)*math.exp(alpha*sigma*alpha*sigma/2)*(special.erf((B-alpha*sigma)/(math.sqrt(2))) - special.erf((A-alpha*sigma)/(math.sqrt(2))) ) * (sigma**2 - (-alpha*sigma**2+K-s1)*(alpha*sigma**2-Q+s1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b071c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def I_u_integrand(s,theta,V,K,S0,sigma0,t1):\n",
    "    return np.exp(-np.sum(V*np.maximum(s-K,0))+K.size*theta*(s-S0))*m_0(s,S0,sigma0,t1)\n",
    "\n",
    "def I_u(theta,V,K,S0,sigma0,t1):\n",
    "    return integrate.quad(I_u_integrand,0,S0+3*sigma0,args=(theta,V,K,S0,sigma0,t1) )[0]\n",
    "\n",
    "\n",
    "\n",
    "def I_h_0_integrand(s,theta,V,K,S0,sigma0,t1):\n",
    "    return np.exp(-np.sum(V*np.maximum(s-K,0))+K.size*theta*(s-S0))*m_0(s,S0,sigma0,t1)*(s-S0)\n",
    "\n",
    "def I_h_0(theta,V,K,S0,sigma0,t1):\n",
    "    return integrate.quad(I_h_0_integrand,0,S0+3*sigma0,args=(theta,V,K,S0,sigma0,t1))[0]\n",
    "\n",
    "\n",
    "def I_h_0_grad_integrand(s,theta,V,K,S0,sigma0,t1):\n",
    "    return np.exp(-np.sum(V*np.maximum(s-K,0))+K.size*theta*(s-S0))*m_0(s,S0,sigma0,t1)*(s-S0)*(s-S0)\n",
    "    \n",
    "def I_h_0_grad(theta,V,K,S_0,sigma0,t1):\n",
    "    return integrate.quad(I_h_0_grad_integrand,0,S0+3*sigma0,args=(theta,V,K,S0,sigma0,t1))[0]\n",
    "\n",
    "\n",
    "def I_h_0_hessian_integrand(s,theta,V,K,S0,sigma0,t1):\n",
    "    return np.exp(-np.sum(V*np.maximum(s-K,0))+K.size*theta*(s-S0))*m0(s,S0,sigma0,t1)*(s-S0)*(s-S0)*(s-S0)\n",
    "\n",
    "def I_h_0_hessian(theta,V,K,S0,sigma0,t1):\n",
    "    return integrate.quad(I_h_0_hessian_integrand,0,S0+3*sigma0,args=(theta,V,K,S0,sigma0,t1))[0]\n",
    "\n",
    "\n",
    "\n",
    "def I_Q_integrand(s,h0,V,K,Q,S0,sigma0,t1):\n",
    "    return math.exp(-np.sum(V*np.maximum(s-K,0))+K.size*h0*(s-S0))*m_0(s,S0,sigma0,t1)*np.maximum(s-Q,0)\n",
    "\n",
    "def I_Q(h0,V,K,Q,S0,sigma0,t1):\n",
    "    return integrate.quad(I_Q_integrand,0,S0+3*sigma0,args=(h0,V,K,Q,S0,sigma0,t1))[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0298f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, n = S0-20, S0+20, 11 # Take odd n, such that X1[(n-1)/2] = S0\n",
    "K1, K2 = a, b\n",
    "X1 = np.linspace(a,b,n) # Discrete grid\n",
    "P1 = lambda x:(1/(np.sqrt(2*math.pi)*1e-1)) * np.exp(-1/2*((x-S0)/1e-1)**2) * (x >= 0) # Approximation of Dirac delta around \n",
    "P1_disc = lambda x: P1(x)/sum(P1(X1))\n",
    "#sum(P1_disc(X1)) = 1\n",
    "#sum(X1*P1_disc(X1)) = 92.3 = S0\n",
    "\n",
    "\n",
    "def integrand_G1(s,V,u0,h0,K,omega,S0,sigma0,t1):\n",
    "    return m_0(s,S0,sigma0,t1)*np.exp(-np.sum(V*np.maximum(s-K,0))+(u0-h0*(s-S0))*K.size) \n",
    "\n",
    "def G1(V,u0,h0,K,omega,S0,sigma0,t1):\n",
    "    expectation = integrate.quad(integrand_G1,0,S0+3*sigma0,args=(V,u0,h0,K,omega,S0,sigma0,t1))[0]\n",
    "    #expectation_other = I_u(h0,V,K,S0,sigma0,t1)*np.exp(-u0) # Gives the same result as the other one! -> Confirms P_sig0 = delta(s-S0)\n",
    "    print (f'G1 = {u0 + np.sum(V*mid) + np.sum(f1(V,omega)) + expectation}')\n",
    "    return u0 + np.sum(V*mid) + np.sum(f1(V,omega)) + expectation\n",
    "\n",
    "    \n",
    "def grad_G1(V,u0,h0,K,omega,S0,sigma0,t1):\n",
    "    \"\"\"\n",
    "    Gradient of G_12 with respect to V_K_i\n",
    "    \"\"\"\n",
    "    grad = np.zeros(numK)\n",
    "    gf1 = grad_f1(V,omega)\n",
    "    for i in range(numK):\n",
    "        grad[i] = gf1[i] + mid[i] - I_Q(h0,V,K,K[i],S0,sigma0,t1)*np.exp(-u0) # Q = K[i] #TODO: can this be sped up by providing Q as a vector?\n",
    "    \n",
    "    print(f'Grad = {grad}')\n",
    "    #print(f'Grad norm = {np.norm(grad)}')\n",
    "    return grad\n",
    "\n",
    "\n",
    "def Hess_G1(V,u0,h0,K,omega,S0,sigma0,t1):\n",
    "    '''\n",
    "    Hessian of G_12\n",
    "    '''\n",
    "    H = np.zeros((numK,numK))\n",
    "    H = np.diag(omega)\n",
    "    \n",
    "    for i in range(numK):\n",
    "        for j in range(numK):\n",
    "            integrand = lambda s: np.maximum((s-K[i]),0)*np.maximum((s-K[j]),0)*np.exp(-np.sum(V*np.maximum(s-K,0))+(u0-h0*(s-S0))*K.size)*m_0(s,S0,sigma0,t1)\n",
    "            H[i,j] += integrate.quad(integrand,0,S0+3*sigma0)[0] \n",
    "    \n",
    "    return H\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ec8163e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad = [-1.34061779 -1.50975514 -1.72926395 -1.92540119 -2.09931341 -2.27701746\n",
      " -2.43438296 -2.54711697 -2.64075125 -2.72563246 -2.75191605 -2.72956306\n",
      " -2.66834106 -2.56282833 -2.42742167 -2.25634733 -2.0736748  -1.88333314\n",
      " -1.68912927 -1.49476767]\n",
      "G1 = 0.9999998658781437\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999998489698612\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.999999827054272\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999998074784152\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997898662669\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997722176321\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997566011457\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997449830005\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997358212679\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997275316914\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997240960921\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997286604975\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997324213349\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997433374712\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997584325798\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.999999773418854\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999997924051313\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999998127278026\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999998302013455\n",
      "G1 = 1.0000000000000002\n",
      "G1 = 0.9999998501748908\n",
      "G1 = 1.0000000000000002\n",
      "Grad = [-1.34061779 -1.50975514 -1.72926395 -1.92540119 -2.09931341 -2.27701746\n",
      " -2.43438296 -2.54711697 -2.64075125 -2.72563246 -2.75191605 -2.72956306\n",
      " -2.66834106 -2.56282833 -2.42742167 -2.25634733 -2.0736748  -1.88333314\n",
      " -1.68912927 -1.49476767]\n",
      "Grad_FD = [-1.34121857 -1.51030139 -1.72945728 -1.92521585 -2.10133733 -2.27782368\n",
      " -2.43398855 -2.55017    -2.64178732 -2.72468309 -2.75903908 -2.71339503\n",
      " -2.67578665 -2.56662529 -2.4156742  -2.26581146 -2.07594869 -1.87272198\n",
      " -1.69798655 -1.49825109]\n"
     ]
    }
   ],
   "source": [
    "def grad_G1_comparison(V,u0,h0,K,omega,S0,sigma0,t1):\n",
    "    '''\n",
    "    Check whether the expression of the gradient is correct, by comparing it to a finite difference approximation\n",
    "    '''\n",
    "    grad = grad_G1(V,u0,h0,K,omega,S0,sigma0,t1)\n",
    "    \n",
    "    grad_FD = np.zeros(numK)\n",
    "    eps = 1e-7\n",
    "    for i in range(numK):\n",
    "        D = np.zeros(numK)\n",
    "        D[i] = eps\n",
    "        grad_FD[i] = (G1(V+D,u0,h0,K,omega,S0,sigma0,t1)-G1(V,u0,h0,K,omega,S0,sigma0,t1))/eps\n",
    "        \n",
    "    print(f'Grad = {grad}')\n",
    "    print(f'Grad_FD = {grad_FD}')\n",
    "\n",
    "u0, h0, V = 0., 0., [0.]*numK\n",
    "p0 = np.array([u1] + [h1] + V)\n",
    "Lambda = 0.1\n",
    "omega_K = Lambda * np.abs(ask - bid)\n",
    "\n",
    "grad_G1_comparison(np.zeros(numK),u0,h0,K,omega_K,S0,sigma0,t1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b875084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad = [-1.3403567  -1.50950499 -1.72902475 -1.92517293 -2.09909606 -2.27681099\n",
      " -2.43418734 -2.54693212 -2.64057709 -2.72546888 -2.7517629  -2.72942018\n",
      " -2.66820822 -2.56270531 -2.4273082  -2.25624308 -2.07357945 -1.88324631\n",
      " -1.68905055 -1.49469664]\n",
      "Grad = [-1.34061779 -1.50975514 -1.72926395 -1.92540119 -2.09931341 -2.27701746\n",
      " -2.43438296 -2.54711697 -2.64075125 -2.72563246 -2.75191605 -2.72956306\n",
      " -2.66834106 -2.56282833 -2.42742167 -2.25634733 -2.0736748  -1.88333314\n",
      " -1.68912927 -1.49476767]\n",
      "Hess_u = [2610.84374531 2501.40628915 2392.00375867 2282.68605244 2173.54025761\n",
      " 2064.68288675 1956.27610316 1848.51779219 1741.63038986 1635.86543637\n",
      " 1531.52891453 1428.91837048 1328.369025   1230.22204964 1134.81218868\n",
      " 1042.48804131  953.5742498   868.37788873  787.18332283  710.23579343]\n",
      "Hess_u_FD = [2610.91606506 2501.47065092 2391.96977626 2282.65307657 2173.50828658\n",
      " 2064.65191915 1956.24610155 1848.48876859 1741.60213697 1635.83826286\n",
      " 1531.50275129 1428.8933139  1328.3450709  1230.19653848 1134.78812061\n",
      " 1042.46539943  953.55296696  868.35803401  787.16474319  710.21865412]\n"
     ]
    }
   ],
   "source": [
    "def Hess_G1_comparison(V,u0,h0,K,omega,S0,sigma0,t1):\n",
    "    '''\n",
    "    Check whether the expression of the Hessian is correct, by comparing it to a finite difference approximation\n",
    "    '''\n",
    "    Hess = Hess_G1(V,u0,h0,K,omega,S0,sigma0,t1)\n",
    "    u = np.ones(numK)\n",
    "    eps = 1e-7\n",
    "    \n",
    "    Hess_u = Hess.dot(u)\n",
    "    Hess_u_FD = (grad_G1(V+eps*u,u0,h0,K,omega,S0,sigma0,t1)-grad_G1(V,u0,h0,K,omega,S0,sigma0,t1))/eps\n",
    "    \n",
    "    print(f'Hess_u = {Hess_u}')\n",
    "    print(f'Hess_u_FD = {Hess_u_FD}')\n",
    "    \n",
    "\n",
    "Hess_G1_comparison(np.zeros(numK),u0,h0,K,omega_K,S0,sigma0,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d1d5b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xx = np.linspace(-0.1,0.1,400)\n",
    "#g = lambda x: I_h_0(x,V,K,S0,sigma_0,t1)\n",
    "#g_ = np.vectorize(g)\n",
    "#plt.plot(xx,g_(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f673d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/6f30xmfd3r3br8s467bvpdg40000gn/T/ipykernel_13145/2347683137.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-np.sum(V*np.maximum(s-K,0))+K.size*theta*(s-S0))*m_0(s,S0,sigma0,t1)*(s-S0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "2.2204460492503128e-16\n",
      "G1 = 1.000000000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeroen/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py:527: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  if not isinstance(args, tuple):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad = [-1.34061779 -1.50975514 -1.72926395 -1.92540119 -2.09931341 -2.27701746\n",
      " -2.43438296 -2.54711697 -2.64075125 -2.72563246 -2.75191605 -2.72956306\n",
      " -2.66834106 -2.56282833 -2.42742167 -2.25634733 -2.0736748  -1.88333314\n",
      " -1.68912927 -1.49476767]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/6f30xmfd3r3br8s467bvpdg40000gn/T/ipykernel_13145/1804031541.py:14: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  expectation = integrate.quad(integrand_G1,0,S0+3*sigma0,args=(V,u0,h0,K,omega,S0,sigma0,t1))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 = 13.65175106848102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/6f30xmfd3r3br8s467bvpdg40000gn/T/ipykernel_13145/2347683137.py:35: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  return integrate.quad(I_Q_integrand,0,S0+3*sigma0,args=(h0,V,K,Q,S0,sigma0,t1))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad = [9.54175135 8.67672889 7.80349639 6.90389296 6.05424459 5.22845292\n",
      " 4.45246104 3.752575   3.10266966 2.49055109 1.97111282 1.53055189\n",
      " 1.16053951 0.86629544 0.6304908  0.46045621 0.33041928 0.2351904\n",
      " 0.17034152 0.13030223]\n",
      "G1 = 2.107242068008423\n",
      "Grad = [8.54776899 7.83216249 7.06678261 6.32622765 5.61088317 4.89671862\n",
      " 4.21062634 3.58009676 2.98269595 2.41102293 1.91851043 1.49729186\n",
      " 1.13983131 0.85300096 0.62293962 0.45598448 0.32777302 0.23377151\n",
      " 0.16936446 0.12967429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/6f30xmfd3r3br8s467bvpdg40000gn/T/ipykernel_13145/1804031541.py:14: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  expectation = integrate.quad(integrand_G1,0,S0+3*sigma0,args=(V,u0,h0,K,omega,S0,sigma0,t1))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 = 0.9905540553734071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/6f30xmfd3r3br8s467bvpdg40000gn/T/ipykernel_13145/2347683137.py:35: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  return integrate.quad(I_Q_integrand,0,S0+3*sigma0,args=(h0,V,K,Q,S0,sigma0,t1))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad = [ 4.74791003  4.2976698   3.79715794  3.32026261  2.86610762  2.40905109\n",
      "  1.97377476  1.58527434  1.21880775  0.86492574  0.57461805  0.3389688\n",
      "  0.1494072   0.01252098 -0.08501694 -0.13635456 -0.16467019 -0.17314464\n",
      " -0.16499827 -0.14356235]\n",
      "G1 = 0.9717182375832676\n",
      "Grad = [ 4.629809    4.19158179  3.70302738  3.23796012  2.79538975  2.34953596\n",
      "  1.9249249   1.54640087  1.18908131  0.84339312  0.56025438  0.33069388\n",
      "  0.14614365  0.01323027 -0.08131103 -0.13051838 -0.15745553 -0.16517742\n",
      " -0.15677437 -0.13545962]\n",
      "G1 = 0.9015429474373842\n",
      "Grad = [ 4.08981943  3.70481015  3.26925045  2.85665344  2.46555579  2.06959488\n",
      "  1.69262154  1.35880566  1.04262338  0.7339189   0.48324589  0.28135255\n",
      "  0.11965042  0.00492193 -0.07581697 -0.11510844 -0.13548498 -0.13941883\n",
      " -0.12940397 -0.10811469]\n",
      "G1 = 0.7624153863495013\n",
      "Grad = [ 2.41742876  2.22419082  1.97977225  1.755923    1.54891048  1.32962514\n",
      "  1.11825134  0.93528266  0.75181177  0.55464931  0.39283862  0.25672928\n",
      "  0.13964817  0.05159952 -0.0164707  -0.05272943 -0.07600559 -0.08584903\n",
      " -0.08282553 -0.06840006]\n",
      "G1 = 0.9820462889947664\n",
      "Grad = [-8.80761355 -8.24415811 -7.72784296 -7.18720531 -6.62287935 -6.05970469\n",
      " -5.47621455 -4.85234106 -4.21909926 -3.59761752 -2.95708261 -2.33118208\n",
      " -1.75693577 -1.25387497 -0.85181334 -0.54200001 -0.33012685 -0.19244403\n",
      " -0.10396813 -0.0446021 ]\n",
      "G1 = 0.7248110321742822\n",
      "Grad = [ 0.5796627   0.50775517  0.38592942  0.28583652  0.20479998  0.11512355\n",
      "  0.0374924  -0.00778045 -0.05040207 -0.10609104 -0.1307649  -0.13932049\n",
      " -0.14370741 -0.13771957 -0.13215731 -0.11414972 -0.09990677 -0.08552969\n",
      " -0.06806855 -0.04607414]\n",
      "G1 = 0.7251077178651569\n",
      "Grad = [-1.05388868 -0.90091928 -0.7977825  -0.67721486 -0.5456395  -0.4346165\n",
      " -0.3292972  -0.21440506 -0.12319109 -0.07456654 -0.02714855  0.00450074\n",
      "  0.01290196  0.01118539 -0.00342902 -0.01074518 -0.02150686 -0.02873884\n",
      " -0.0284224  -0.01912731]\n",
      "G1 = 0.7126965221455804\n",
      "Grad = [-0.13487602 -0.10578625 -0.1263606  -0.12733114 -0.11308938 -0.11301933\n",
      " -0.10902983 -0.08296623 -0.06606792 -0.07548455 -0.068385   -0.05964158\n",
      " -0.05935274 -0.05830886 -0.06367579 -0.05912184 -0.05816233 -0.05530796\n",
      " -0.04701217 -0.03180493]\n",
      "G1 = 0.7108412895883074\n",
      "Grad = [-0.23235558 -0.19136791 -0.19956765 -0.18922866 -0.16559333 -0.15801267\n",
      " -0.149041   -0.12016313 -0.10104839 -0.10733194 -0.09606315 -0.08165093\n",
      " -0.07440477 -0.06599675 -0.06470087 -0.05516926 -0.05114765 -0.04695461\n",
      " -0.03854278 -0.02394762]\n",
      "G1 = 0.7079672441629642\n",
      "Grad = [-0.20158487 -0.15799177 -0.16013429 -0.14589836 -0.12128098 -0.11464343\n",
      " -0.10985877 -0.08775516 -0.07472201 -0.08404041 -0.07388595 -0.05853466\n",
      " -0.04864682 -0.03707442 -0.03343042 -0.0236126  -0.02135657 -0.02051582\n",
      " -0.01621349 -0.00576469]\n",
      "G1 = 0.7046519937051632\n"
     ]
    }
   ],
   "source": [
    "h0 = optimize.root_scalar(I_h_0,args=(V,K,S0,sigma0,t1) ,bracket = [-1,1],x0=0.00005, fprime = I_h_0_grad, fprime2 = I_h_0_hessian).root\n",
    "#u1 = -math.log(1/(I_u(h1,V,K,s1,sigma_0,t1)))\n",
    "u0 = np.log(I_u(h0,V,K,S0,sigma0,t1))\n",
    "print(h0)\n",
    "print(u0)\n",
    "    \n",
    "\n",
    "V_star = optimize.minimize(fun= G1, x0=V, args=(u0,h0,K,omega_K,S0,sigma0,t1), method='BFGS', jac= grad_G1, hess=Hess_G1, hessp=None, bounds=None, constraints=(), tol=1e-2, callback=None, options=None).x\n",
    "print(V_star)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "da218a66",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c6365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c05cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f485fdd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68b98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643996c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f86092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276fb66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67adfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df98c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c190f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea4152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64443a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef9c6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca07cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f6b85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baaaa9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768bba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e88b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42944f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a051a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6c6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab15b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29a254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
